{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd5226b",
   "metadata": {},
   "source": [
    "# 读入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d45561f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:35.307974Z",
     "start_time": "2023-11-26T08:10:33.617326Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']\n"
     ]
    }
   ],
   "source": [
    "import jiagu\n",
    "import string\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as  np\n",
    "import cn_clip.clip as clip\n",
    "from cn_clip.clip import load_from_name, available_models\n",
    "import itertools\n",
    "import jiagu\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import fitz # PyMuPDF\n",
    "import pdb\n",
    "import ast\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Available models:\", available_models())\n",
    "# Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cae015",
   "metadata": {},
   "source": [
    "# 读入文本和图片信息的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ea5400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:41.036716Z",
     "start_time": "2023-11-26T08:10:35.935148Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读入文本DataFrame\n",
    "df_text = pd.read_excel(\"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/01_Extraction/Test01/01 text/text_df_3.xlsx\")\n",
    "# df_text = pd.read_excel(\"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/03_TextImgMatch/partly/文本提取_text_df_2.xlsx\")\n",
    "\n",
    "# 读入图片DataFrame\n",
    "df_img = pd.read_excel(\"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/01_Extraction/Test01/03 PyMu_img01_coordinate/cord_final2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd93c63",
   "metadata": {},
   "source": [
    "# 函数定义\n",
    "## 去除字段中的标点和空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f49bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:48.182556Z",
     "start_time": "2023-11-26T08:10:48.176764Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation_and_spaces(text):\n",
    "    # 去除标点符号\n",
    "    text = str(text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # 去除空格\n",
    "    text = re.sub(r\"\\s+\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55243a",
   "metadata": {},
   "source": [
    "## 从文本段中提取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a1ca96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:49.615468Z",
     "start_time": "2023-11-26T08:10:49.611014Z"
    }
   },
   "outputs": [],
   "source": [
    "# fin = open('GS.txt', mode='r',encoding='UTF-8')\n",
    "# text = fin.read()\n",
    "# fin.close()\n",
    "\n",
    "def labelization(text, key_num = 3):\n",
    "#     summarize = jiagu.summarize(text, 1) # 摘要\n",
    "#     print(\"Sum:\", summarize)\n",
    "#     keywords = jiagu.keywords(text, 15) # 关键词\n",
    "#     print(\"\\nKeyWords:\", keywords)\n",
    "\n",
    "    cleaned_sentence = remove_punctuation_and_spaces(text)\n",
    "#     print(\"\\nCleaned Sentence:\", cleaned_sentence)\n",
    "    # summarize1 = jiagu.summarize(cleaned_sentence, 1) # 摘要\n",
    "    # print(summarize1)\n",
    "    keywords1 = jiagu.keywords(cleaned_sentence, key_num) # 关键词\n",
    "#     print(\"KeyWords:\", keywords1,\"\\n\\n\")\n",
    "    \n",
    "    return keywords1\n",
    "# fin = open('input.txt', 'r')\n",
    "# text = fin.read()\n",
    "# fin.close()\n",
    "#\n",
    "# summarize = jiagu.summarize(text, 3) # 摘要\n",
    "# print(summarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68735b0",
   "metadata": {},
   "source": [
    "## 提取当页全部关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3f1523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:51.089352Z",
     "start_time": "2023-11-26T08:10:51.082729Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keywords(PDF_name, page):\n",
    "    keywords_list = []\n",
    "    keyword = []\n",
    "#     page = page + 1\n",
    "    \n",
    "#     unique_pages = df_text[df_text[\"PDF_name\"] == PDF_name]['page'].unique()\n",
    "#     for page in unique_pages:\n",
    "#         # 指定要获取的行\n",
    "    page_rows = df_text[(df_text[\"PDF_name\"] == PDF_name) & (df_text['page'] == page)]\n",
    "\n",
    "\n",
    "    for idx, row in page_rows.iterrows():\n",
    "        # 提取关键词\n",
    "        if not pd.isna(row['content']):\n",
    "            keywords = labelization(row['content'], len(str(row['content'])) // 20 + 2)\n",
    "#         print(keywords)\n",
    "        # 将关键词保存至特定行的'keyword'列\n",
    "        df_text['keyword'] = df_text['keyword'].astype('object')\n",
    "#         df_text.loc[idx, \"keyword\"] = keywords\n",
    "        df_text.at[idx, 'keyword'] = keywords\n",
    "\n",
    "        # 加入当前页的总'keyword_list'\n",
    "        keywords_list.append(keywords)\n",
    "        keyword = list(itertools.chain.from_iterable(keywords_list))\n",
    "    \n",
    "    return keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd5c35",
   "metadata": {},
   "source": [
    "## 获取特定图片在当页标签中的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d73171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:52.809711Z",
     "start_time": "2023-11-26T08:10:52.802035Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_path = \"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/01_Extraction/Test01/02 PyMu_img01/00941.HK-中国移动-中国移动 2022年度可持续发展报告-2023-03-24.pdf_page_10_img_1.png\"\n",
    "\n",
    "# keywords = [keyword for keyword in keywords_list if pattern.match(keyword)]\n",
    "\n",
    "def jiagu_prob(img_path, keywords):\n",
    "    # 预处理，读入模型\n",
    "    device='cpu'\n",
    "    model, preprocess = load_from_name(\"RN50\", device=device, download_root='./')\n",
    "    model.eval()\n",
    "\n",
    "    # 转移到mps上进行gpu加速\n",
    "    device = \"mps\" if torch.backends.mps.is_available() == True else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    image = preprocess(Image.open(img_path)).unsqueeze(0).to(device)\n",
    "    label = clip.tokenize(keywords).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(label)\n",
    "        # 对特征进行归一化，用于下游任务\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        logits_per_image, logits_per_text = model.get_similarity(image, label)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    return probs, img_path\n",
    "\n",
    "# print(\"\\nLabel probs:\", probs)  # [[1.268734e-03 5.436878e-02 6.795761e-04 9.436829e-01]]\n",
    "# labels = keywords\n",
    "# max_prob_index = np.argmax(probs)\n",
    "# max_prob_label = labels[max_prob_index]\n",
    "# print(\"\\nMax probability label:\", max_prob_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab93f8",
   "metadata": {},
   "source": [
    "## 图片匹配文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e9c496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:53.960322Z",
     "start_time": "2023-11-26T08:10:53.949071Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_match_img(labels, probs, img_path, PDF_name, page, df_text = df_text, df_img = df_img):\n",
    "    \"\"\"\n",
    "    将每个图片最配对文本保留在df_img中\n",
    "    将最配对文本的可信度（CRI）保留\n",
    "    \"\"\"\n",
    "    # 创建一个标签到概率的映射字典\n",
    "    prob_dict = dict(zip(labels, probs[0]))\n",
    "#     print(\"\\nProb_Dict:\\n\", prob_dict, \"\\n\\n\\n\")\n",
    "    filtered_df = df_text[(df_text[\"PDF_name\"] == PDF_name) & (df_text['page'] == page)]\n",
    "    if not filtered_df.empty:\n",
    "        filtered_df = filtered_df[pd.notnull(filtered_df['keyword'])]\n",
    "\n",
    "        # 创建一个新列来存储每个标签组的概率总和\n",
    "        filtered_df['prob_sum'] = filtered_df['keyword'].apply(\n",
    "            lambda keywords: sum(prob_dict.get(k, 0) for k in keywords if pd.notnull(k)) / \n",
    "                             (len([k for k in keywords if pd.notnull(k)]) if keywords else 1)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # 使用 apply() 方法遍历列\n",
    "        filtered_df['prob_sum'] = filtered_df['prob_sum'].apply(lambda x: 0.0 if not isinstance(x, float) else x)\n",
    "#         print(\"\\nFiltered_df:\\n\",filtered_df, \"\\n\")\n",
    "        \n",
    "        if not filtered_df['prob_sum'].empty:\n",
    "            max_prob_content = filtered_df.loc[filtered_df['prob_sum'].idxmax(), 'content']\n",
    "            max_prob = filtered_df['prob_sum'].max()\n",
    "            cri = CRI(filtered_df)\n",
    "        else:\n",
    "        # 如果 prob_sum 列为空\n",
    "            max_prob_content = None  # 或任何合适的默认值\n",
    "            max_prob = None\n",
    "            cri = None\n",
    "\n",
    "        # 获取图片名称并存储至df_img\n",
    "        img_name = os.path.basename(img_path)\n",
    "        df_img.loc[df_img[\"file_name\"] == img_name, \"match_text\"] = max_prob_content\n",
    "        df_img.loc[df_img[\"file_name\"] == img_name, \"match_text_prob\"] = max_prob\n",
    "        df_img.loc[df_img[\"file_name\"] == img_name, \"match_text_CRI\"] = cri\n",
    "        \n",
    "        return max_prob_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de15308",
   "metadata": {},
   "source": [
    "## 计算标签组概率的可靠性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34c786c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:54.972012Z",
     "start_time": "2023-11-26T08:10:54.966579Z"
    }
   },
   "outputs": [],
   "source": [
    "def CRI(filtered_df):\n",
    "    \"\"\"\n",
    "    综合可靠性指数(Composite Reliability Index, CRI)\n",
    "        计算: 最大概率差异度(Maximum Probability Spread, MPS) / 标准差(Standard Deviation, SD)\n",
    "    \n",
    "    最大概率差异度(Maximum Probability Spread, MPS): \n",
    "        计算: 最大概率值与其他概率值的差值，然后取平均值。\n",
    "    \"\"\"\n",
    "    # 计算MPS和SD\n",
    "    max_probability = filtered_df['prob_sum'].max()  # 最大概率值\n",
    "    average_probability = filtered_df['prob_sum'].mean()  # 所有概率的平均值\n",
    "    probabilities_except_max = filtered_df[filtered_df['prob_sum'] != max_probability]['prob_sum']  # 除了最大值的所有概率值\n",
    "\n",
    "    # 计算MPS\n",
    "    mps = max_probability - probabilities_except_max.mean() if not probabilities_except_max.empty else 0\n",
    "\n",
    "    # 计算标准差\n",
    "    sd = filtered_df['prob_sum'].std()  # 所有概率值的标准差\n",
    "\n",
    "    # 计算CRI\n",
    "    cri = mps / sd if sd > 0 else 0  # 如果标准差为0，则CRI没有意义\n",
    "    \n",
    "    return cri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caf2a2",
   "metadata": {},
   "source": [
    "## 一次获取PDF中每一页的全部标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a00096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:56.958212Z",
     "start_time": "2023-11-26T08:10:56.952955Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_in_PDF(PDF_path):\n",
    "    pdf_file = fitz.open(PDF_path)\n",
    "    pdf_name = os.path.basename(PDF_path)\n",
    "\n",
    "    key = []\n",
    "\n",
    "    # 遍历PDF的每一页\n",
    "    for page in tqdm(range(len(pdf_file))):\n",
    "        keywords = extract_keywords(pdf_name, page)\n",
    "    #     print(\"Page:{}\\n{}\\n\\n\".format(page,keywords))\n",
    "        key.append({'file_name': pdf_name,\n",
    "                    'page': page + 1,\n",
    "                    'keywords': keywords})\n",
    "\n",
    "    # 创建临时df存放每一页的关键词组 \n",
    "    df_key = pd.DataFrame(key)\n",
    "    \n",
    "    return df_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7683ed",
   "metadata": {},
   "source": [
    "## 计算距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0129b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:57.897698Z",
     "start_time": "2023-11-26T08:10:57.894132Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(img_cord, text_cord):\n",
    "    \"\"\"\n",
    "    Takes in both 'img_cord' and 'text_cord' in tuple of (x, y).\n",
    "    Return the distance between two cord.\n",
    "    \"\"\"\n",
    "    img_x, img_y = img_cord\n",
    "    text_x, text_y = text_cord\n",
    "    \n",
    "    return math.sqrt((text_x - img_x)**2 + (text_y - img_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d079540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:10:59.648450Z",
     "start_time": "2023-11-26T08:10:59.644008Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bundle_path(directory):\n",
    "    files = [f for f in os.listdir(directory) if f != '.DS_Store']\n",
    "    return [os.path.join(directory, file) for file in files if os.path.isfile(os.path.join(directory, file))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9b988",
   "metadata": {},
   "source": [
    "# 计算最近的图文间的语义匹配度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e946efe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:11:00.809762Z",
     "start_time": "2023-11-26T08:11:00.800128Z"
    }
   },
   "outputs": [],
   "source": [
    "def wording_similarity(labels, probs, img_path, PDF_name, page, df_text = df_text, df_img = df_img):\n",
    "    # 创建一个标签到概率的映射字典\n",
    "    prob_dict = dict(zip(labels, probs[0]))\n",
    "    \n",
    "    # 获得图片坐标\n",
    "    img_name = os.path.basename(img_path)\n",
    "    img_cord = df_img[df_img['file_name'] == img_name]['centre_coordinate']\n",
    "    [img_cord] = img_cord.values\n",
    "    img_cord = ast.literal_eval(img_cord)\n",
    "        \n",
    "    # 获取文本段坐标\n",
    "    df_min_dis = df_text.loc[(df_text['PDF_name'] == os.path.basename(PDF_path)) & (df_text['page'] == page)]\n",
    "#     df_min_dis = df_min_dis(pd.notnull(df_min_dis['keyword']))\n",
    "    if not df_min_dis.empty:\n",
    "        df_min_dis['dis_to_img_current'] = df_min_dis.apply(lambda row: distance(img_cord, (row['center_x'], row['center_y'])), axis = 1)\n",
    "    else:\n",
    "        print(\"{0:=^40}\".format('Anomaly Founded'))\n",
    "        print(\"PDF:{} has no text content on page{}\".format(PDF_name, page))\n",
    "    \n",
    "    # 计算标签组概率\n",
    "    return df_min_dis.sort_values(by='dis_to_img_current', ascending = True)[0:1]['keyword'].apply(\n",
    "        lambda keywords: sum(prob_dict.get(k, 0) for k in keywords if pd.notnull(k)) /\n",
    "                         (len([k for k in keywords if pd.notnull(k)]) if keywords else 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ed942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:06:49.274410Z",
     "start_time": "2023-11-26T08:06:47.361654Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = '/Users/improvise/Desktop/保研/实证论文/ESG/Playground/01_Extraction/Test01/02 PyMu_img01/00941.HK-中国移动-中国移动 2022年度可持续发展报告-2023-03-24.pdf_page_7_img_1.png'\n",
    "PDF_path = '/Users/improvise/Desktop/保研/实证论文/ESG/Playground/00_DataBase/00_SustainabilityReport_PDF/2022/00941.HK-中国移动-中国移动 2022年度可持续发展报告-2023-03-24.pdf'\n",
    "df_key = label_in_PDF(PDF_path)\n",
    "[keywords] = list(df_key.loc[(df_key['file_name'] == os.path.basename(PDF_path)) & (df_key['page'] == 8)]['keywords'])\n",
    "\n",
    "probs, img_path = jiagu_prob(img_path, keywords)\n",
    "\n",
    "wording_similarity(keywords, probs, img_path, os.path.basename(PDF_path), page=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ce322",
   "metadata": {},
   "source": [
    "# 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6309165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T08:17:55.261037Z",
     "start_time": "2023-11-16T08:17:55.258887Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定要处理的PDF路径\n",
    "# PDF_path = \"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/00_DataBase/00_SustainabilityReport_PDF/2022/00941.HK-中国移动-中国移动 2022年度可持续发展报告-2023-03-24.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35335690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:11:15.149241Z",
     "start_time": "2023-11-26T08:11:15.146343Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定要处理的PDF文件夹\n",
    "# folder_dir = \"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/00_DataBase/00_SustainabilityReport_PDF/2022\"\n",
    "folder_dir = \"/Users/improvise/Downloads/test\"\n",
    "\n",
    "# 指定要处理的图片文件夹\n",
    "img_folder = \"/Users/improvise/Desktop/保研/实证论文/ESG/Playground/01_Extraction/Test01/02 PyMu_img01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224bf9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:13:19.537994Z",
     "start_time": "2023-11-26T08:11:16.087250Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:02<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n",
      "Loading vision model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RN50.json\n",
      "Loading text model config from /Users/improvise/miniconda/envs/Grace/lib/python3.9/site-packages/Chinese-CLIP-master/cn_clip/clip/model_configs/RBT3-chinese.json\n",
      "Model info {'embed_dim': 1024, 'image_resolution': 224, 'vision_layers': [3, 4, 6, 3], 'vision_width': 64, 'vision_patch_size': None, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 3, 'text_type_vocab_size': 2}\n"
     ]
    }
   ],
   "source": [
    "PDF_path_list = get_bundle_path(folder_dir)\n",
    "\n",
    "for PDF_path in PDF_path_list:\n",
    "    df_key = label_in_PDF(PDF_path)\n",
    "    for row in df_img.loc[df_img['PDF_name']==os.path.basename(PDF_path)].itertuples():\n",
    "        img_name = row.file_name\n",
    "        page = row.page\n",
    "        p_index = row.p_index\n",
    "        img_cord = row.centre_coordinate\n",
    "\n",
    "        # 读图\n",
    "        img_path = os.path.join(img_folder, img_name)\n",
    "        # 读页面关键词\n",
    "        [keywords] = list(df_key.loc[(df_key['file_name'] == os.path.basename(PDF_path)) & (df_key['page'] == page)]['keywords'])\n",
    "        # 计算概率\n",
    "        probs, img_path = jiagu_prob(img_path, keywords)\n",
    "\n",
    "        # 匹配图文\n",
    "        object_text = text_match_img(keywords, probs, img_path, os.path.basename(PDF_path), page)\n",
    "        if object_text != None:\n",
    "        # 获取文本坐标\n",
    "            text_cord_list = df_text.loc[(df_text['PDF_name'] == os.path.basename(PDF_path)) & (df_text['page'] == page) & (df_text['content'] == object_text)][['center_x','center_y']].values.tolist()\n",
    "\n",
    "            if text_cord_list:\n",
    "                text_cord = text_cord_list[0]  # 选择第一个元素\n",
    "\n",
    "            # 接下来的计算\n",
    "            else:\n",
    "                [text_cord] = text_cord_list\n",
    "\n",
    "            # 计算距离\n",
    "            if type(img_cord) == str:\n",
    "                    img_cord = ast.literal_eval(img_cord)\n",
    "\n",
    "            dist = distance(img_cord, text_cord)\n",
    "            df_img.loc[df_img[\"file_name\"] == img_name, \"distance\"] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0494700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T08:25:24.793124Z",
     "start_time": "2023-11-16T08:25:24.788588Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for row in df_img.loc[df_img['PDF_name']==os.path.basename(PDF_path)].itertuples():\n",
    "#     img_name = row.file_name\n",
    "#     page = row.page\n",
    "#     p_index = row.p_index\n",
    "#     img_cord = row.centre_coordinate\n",
    "    \n",
    "#     # 读图\n",
    "#     img_path = os.path.join(img_folder, img_name)\n",
    "#     # 读页面关键词\n",
    "#     [keywords] = list(df_key.loc[(df_key['file_name'] == os.path.basename(PDF_path)) & (df_key['page'] == page)]['keywords'])\n",
    "#     # 计算概率\n",
    "#     probs, img_path = jiagu_prob(img_path, keywords)\n",
    "    \n",
    "#     # 匹配图文\n",
    "#     object_text = text_match_img(keywords, probs, img_path, os.path.basename(PDF_path), page)\n",
    "#     if object_text != None:\n",
    "#     # 获取文本坐标\n",
    "#         text_cord_list = df_text.loc[(df_text['PDF_name'] == os.path.basename(PDF_path)) & (df_text['page'] == page) & (df_text['content'] == object_text)][['center_x','center_y']].values.tolist()\n",
    "\n",
    "#         if text_cord_list:\n",
    "#             text_cord = text_cord_list[0]  # 选择第一个元素\n",
    "            \n",
    "#         # 接下来的计算\n",
    "#         else:\n",
    "#             [text_cord] = text_cord_list\n",
    "        \n",
    "#         # 计算距离\n",
    "#         if type(img_cord) == str:\n",
    "#                 img_cord = ast.literal_eval(img_cord)\n",
    "\n",
    "#         dist = distance(img_cord, text_cord)\n",
    "#         df_img.loc[df_img[\"file_name\"] == img_name, \"distance\"] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a9a792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T08:13:44.204880Z",
     "start_time": "2023-11-26T08:13:43.249078Z"
    }
   },
   "outputs": [],
   "source": [
    "df_img.to_excel(\"/Users/improvise/Downloads/distance.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
